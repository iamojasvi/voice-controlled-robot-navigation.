pip install vosk numpy sounddevice
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import queue
import sounddevice as sd
import vosk
import json

class SpeechToText(Node):
    def __init__(self):
        super().__init__('speech_to_text')
        self.publisher_ = self.create_publisher(String, 'voice_commands', 10)
        self.model = vosk.Model("path/to/vosk-model-small-en-us-0.15")  # Download a Vosk model
        self.q = queue.Queue()
        
        # Start listening
        self.stream = sd.InputStream(callback=self.callback, samplerate=16000, channels=1)
        self.stream.start()

    def callback(self, indata, frames, time, status):
        self.q.put(bytes(indata))

    def process_audio(self):
        rec = vosk.KaldiRecognizer(self.model, 16000)
        while rclpy.ok():
            data = self.q.get()
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                command = result.get("text", "")
                if command:
                    self.publish_command(command)

    def publish_command(self, command):
        msg = String()
        msg.data = command
        self.publisher_.publish(msg)
        self.get_logger().info(f"Recognized Command: {command}")

def main(args=None):
    rclpy.init(args=args)
    node = SpeechToText()
    node.process_audio()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()

        
